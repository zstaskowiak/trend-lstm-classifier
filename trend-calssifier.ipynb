{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10202102,"sourceType":"datasetVersion","datasetId":6304564}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Trend Classification Model (LSTM)\n*Author: Zuzanna Staśkowiak","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load your original dataset with labels\ndata_path = \"/kaggle/input/trends/classified_trends_data.xlsx\"\ndata = pd.read_excel(data_path)\n\n# Tworzymy pusty DataFrame na uporządkowane dane\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:17.228707Z","iopub.execute_input":"2024-12-15T16:32:17.229124Z","iopub.status.idle":"2024-12-15T16:32:17.346187Z","shell.execute_reply.started":"2024-12-15T16:32:17.229090Z","shell.execute_reply":"2024-12-15T16:32:17.345086Z"}},"outputs":[],"execution_count":476},{"cell_type":"code","source":"processed_data = pd.DataFrame()\nfor col in data.columns:\n    temp_df = data[col].str.split(',', expand=True)\n    temp_df.columns = ['Date', col]\n    if 'Date' not in processed_data.columns:\n        processed_data['Date'] = temp_df['Date']\n    processed_data[col] = pd.to_numeric(temp_df[col], errors='coerce')\n\nprocessed_data = processed_data.dropna()\nprocessed_data = processed_data.drop(columns=['Date'], errors='ignore')\n\n\nprint(processed_data.head())\nkk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:17.348428Z","iopub.execute_input":"2024-12-15T16:32:17.348927Z","iopub.status.idle":"2024-12-15T16:32:17.474818Z","shell.execute_reply.started":"2024-12-15T16:32:17.348877Z","shell.execute_reply":"2024-12-15T16:32:17.473386Z"}},"outputs":[{"name":"stdout","text":"   trend  trend.1  trend.2  trend.3  trend.4  no trend  micro trend  \\\n0   55.0     55.0     48.0     84.0     83.0      28.0        100.0   \n1   49.0     53.0     44.0    100.0     99.0      27.0         99.0   \n2   18.0     50.0     60.0     79.0     67.0      22.0         51.0   \n3   57.0     52.0     50.0     76.0     65.0      28.0         38.0   \n4   58.0     65.0     59.0     74.0     61.0      35.0         39.0   \n\n   micro trend.1  micro trend.2  trend.5  ...  micro trend.18  trend.18  \\\n0           86.0            6.0     49.0  ...               6        46   \n1          100.0            6.0     45.0  ...               5        46   \n2           84.0            6.0     45.0  ...               4        45   \n3           54.0            6.0     50.0  ...               3        46   \n4           48.0            6.0     45.0  ...               0        74   \n\n   micro trend.19  no trend.28  micro trend.20  trend.19  no trend.29  \\\n0            18.0         27.0             0.0      64.0         32.0   \n1            13.0        100.0             0.0      56.0         30.0   \n2            10.0         62.0             0.0      69.0         73.0   \n3            14.0         36.0             0.0      88.0         52.0   \n4            15.0         23.0             0.0      97.0         59.0   \n\n   trend.20  trend.21  trend.22  \n0      87.0       0.0      68.0  \n1      75.0       0.0      69.0  \n2      78.0       0.0      77.0  \n3      98.0       0.0     100.0  \n4      84.0       0.0      55.0  \n\n[5 rows x 74 columns]\n","output_type":"stream"}],"execution_count":477},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\ncolumns = processed_data.columns\n\ndef classify_column(name):\n    if 'micro trend' in name:\n        return 'micro trend'\n    elif 'no trend' in name:\n        return 'no trend'\n    elif 'trend' in name:\n        return 'trend'\n    return 'other'  # Domyślnie, w razie jakiejś innej kolumny\n\n# Zastosowanie tej mapy na nazwach kolumn\nclass_names = [classify_column(col) for col in columns]\n\n# Wydrukowanie wyników\n# print(class_names)\nlabel_encoder = LabelEncoder()\nclass_encoded = label_encoder.fit_transform(class_names)\n# print(class_encoded)\n\nprocessed_data = processed_data.transpose()\n# print(processed_data)\nscaler = MinMaxScaler()\nprocessed_data[:] = scaler.fit_transform(processed_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:17.476198Z","iopub.execute_input":"2024-12-15T16:32:17.476567Z","iopub.status.idle":"2024-12-15T16:32:17.491123Z","shell.execute_reply.started":"2024-12-15T16:32:17.476515Z","shell.execute_reply":"2024-12-15T16:32:17.489698Z"}},"outputs":[],"execution_count":478},{"cell_type":"code","source":"X = processed_data.values  # Features: all columns (the sequences)\n\ny = class_encoded\nX = X.reshape(X.shape[0], X.shape[1], 1)\nX = pad_sequences(X, padding='post', dtype='float32')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:17.494308Z","iopub.execute_input":"2024-12-15T16:32:17.494810Z","iopub.status.idle":"2024-12-15T16:32:17.507821Z","shell.execute_reply.started":"2024-12-15T16:32:17.494769Z","shell.execute_reply":"2024-12-15T16:32:17.506390Z"}},"outputs":[],"execution_count":479},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Oversampling za pomocą SMOTE\nX_resampled, y_resampled = SMOTE().fit_resample(X.reshape(X.shape[0], -1), y)\n\n# Dopasowanie kształtu X do pierwotnego formatu\nX = X_resampled.reshape(X_resampled.shape[0], X.shape[1], X.shape[2])\ny = y_resampled\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:17.509251Z","iopub.execute_input":"2024-12-15T16:32:17.509620Z","iopub.status.idle":"2024-12-15T16:32:17.531598Z","shell.execute_reply.started":"2024-12-15T16:32:17.509586Z","shell.execute_reply":"2024-12-15T16:32:17.530678Z"}},"outputs":[],"execution_count":480},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import GRU\n\n\n# Define the LSTM model\nmodel = Sequential()\n# model.add(GRU(10, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n# Add the LSTM layer\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import BatchNormalization\n\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(10, return_sequences=False), input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(BatchNormalization())  # Dodanie normalizacji\nmodel.add(Dropout(0.3))  # Zwiększenie dropout\nmodel.add(Dense(3, activation='softmax'))\n\n# model.add(Bidirectional(LSTM(64, return_sequences=False), input_shape=(X_train.shape[1], X_train.shape[2])))\n# model.add(LSTM(25, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n# model.add(Dropout(0.2))\n# model.add(Dense(3, activation='softmax')) \n\nmodel.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:17.532586Z","iopub.execute_input":"2024-12-15T16:32:17.532922Z","iopub.status.idle":"2024-12-15T16:32:17.648845Z","shell.execute_reply.started":"2024-12-15T16:32:17.532888Z","shell.execute_reply":"2024-12-15T16:32:17.647734Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_65\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_65\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional_15                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m960\u001b[0m │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │            \u001b[38;5;34m80\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m63\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional_15                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,103\u001b[0m (4.31 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,103</span> (4.31 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,063\u001b[0m (4.15 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,063</span> (4.15 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m40\u001b[0m (160.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> (160.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":481},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import KFold\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n# model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_test, y_test), callbacks=[early_stopping])\n# K-Fold Cross Validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    # Trening modelu w każdej iteracji\n    history = model.fit(X_train, y_train, epochs=50, batch_size=15, validation_data=(X_test, y_test))\n\n    # Ewaluacja modelu\n    test_loss, test_acc = model.evaluate(X_test, y_test)\n    print(f'Test accuracy for fold: {test_acc}')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:32:17.650091Z","iopub.execute_input":"2024-12-15T16:32:17.650418Z","iopub.status.idle":"2024-12-15T16:33:03.018675Z","shell.execute_reply.started":"2024-12-15T16:32:17.650385Z","shell.execute_reply":"2024-12-15T16:33:03.017462Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.1917 - loss: 2.2683 - val_accuracy: 0.5000 - val_loss: 1.1490\nEpoch 2/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2111 - loss: 2.2367 - val_accuracy: 0.5000 - val_loss: 1.1444\nEpoch 3/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1796 - loss: 2.3221 - val_accuracy: 0.5000 - val_loss: 1.1394\nEpoch 4/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2102 - loss: 1.9977 - val_accuracy: 0.5556 - val_loss: 1.1335\nEpoch 5/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2222 - loss: 1.9761 - val_accuracy: 0.5556 - val_loss: 1.1275\nEpoch 6/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2241 - loss: 1.7240 - val_accuracy: 0.5556 - val_loss: 1.1212\nEpoch 7/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2667 - loss: 1.5475 - val_accuracy: 0.5000 - val_loss: 1.1143\nEpoch 8/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4167 - loss: 1.3846 - val_accuracy: 0.5000 - val_loss: 1.1076\nEpoch 9/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2731 - loss: 1.7368 - val_accuracy: 0.5000 - val_loss: 1.1012\nEpoch 10/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3676 - loss: 1.5311 - val_accuracy: 0.5000 - val_loss: 1.0947\nEpoch 11/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3722 - loss: 1.3077 - val_accuracy: 0.5000 - val_loss: 1.0875\nEpoch 12/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 1.1709 - val_accuracy: 0.5000 - val_loss: 1.0799\nEpoch 13/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4481 - loss: 1.2606 - val_accuracy: 0.5556 - val_loss: 1.0726\nEpoch 14/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3926 - loss: 1.3584 - val_accuracy: 0.5000 - val_loss: 1.0652\nEpoch 15/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5204 - loss: 1.1434 - val_accuracy: 0.5556 - val_loss: 1.0573\nEpoch 16/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5593 - loss: 1.0176 - val_accuracy: 0.5556 - val_loss: 1.0490\nEpoch 17/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5417 - loss: 1.0524 - val_accuracy: 0.6667 - val_loss: 1.0403\nEpoch 18/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6204 - loss: 0.9746 - val_accuracy: 0.7222 - val_loss: 1.0327\nEpoch 19/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4796 - loss: 1.1897 - val_accuracy: 0.7222 - val_loss: 1.0249\nEpoch 20/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5231 - loss: 1.0032 - val_accuracy: 0.8333 - val_loss: 1.0156\nEpoch 21/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5463 - loss: 0.8947 - val_accuracy: 0.8333 - val_loss: 1.0063\nEpoch 22/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5620 - loss: 0.9514 - val_accuracy: 0.8333 - val_loss: 0.9957\nEpoch 23/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5972 - loss: 0.9332 - val_accuracy: 0.8333 - val_loss: 0.9849\nEpoch 24/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5713 - loss: 0.9867 - val_accuracy: 0.8333 - val_loss: 0.9737\nEpoch 25/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5991 - loss: 0.8485 - val_accuracy: 0.8333 - val_loss: 0.9610\nEpoch 26/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6037 - loss: 0.8603 - val_accuracy: 0.8333 - val_loss: 0.9494\nEpoch 27/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5741 - loss: 0.8055 - val_accuracy: 0.8333 - val_loss: 0.9367\nEpoch 28/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6083 - loss: 0.7990 - val_accuracy: 0.8333 - val_loss: 0.9237\nEpoch 29/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6250 - loss: 0.7617 - val_accuracy: 0.8333 - val_loss: 0.9114\nEpoch 30/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6120 - loss: 0.8057 - val_accuracy: 0.7778 - val_loss: 0.8956\nEpoch 31/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5741 - loss: 0.7768 - val_accuracy: 0.7778 - val_loss: 0.8820\nEpoch 32/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6713 - loss: 0.7564 - val_accuracy: 0.7778 - val_loss: 0.8672\nEpoch 33/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6528 - loss: 0.6651 - val_accuracy: 0.7778 - val_loss: 0.8487\nEpoch 34/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6824 - loss: 0.6480 - val_accuracy: 0.8333 - val_loss: 0.8290\nEpoch 35/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5519 - loss: 0.9135 - val_accuracy: 0.8333 - val_loss: 0.8124\nEpoch 36/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6194 - loss: 0.6950 - val_accuracy: 0.8333 - val_loss: 0.7989\nEpoch 37/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7037 - loss: 0.6897 - val_accuracy: 0.8889 - val_loss: 0.7912\nEpoch 38/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6815 - loss: 0.6439 - val_accuracy: 0.8333 - val_loss: 0.7769\nEpoch 39/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7083 - loss: 0.5761 - val_accuracy: 0.8333 - val_loss: 0.7609\nEpoch 40/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5630 - loss: 0.7687 - val_accuracy: 0.8333 - val_loss: 0.7469\nEpoch 41/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6435 - loss: 0.6716 - val_accuracy: 0.8333 - val_loss: 0.7311\nEpoch 42/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6750 - loss: 0.5909 - val_accuracy: 0.8333 - val_loss: 0.7071\nEpoch 43/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6778 - loss: 0.6643 - val_accuracy: 0.8333 - val_loss: 0.6928\nEpoch 44/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6907 - loss: 0.6641 - val_accuracy: 0.8333 - val_loss: 0.6773\nEpoch 45/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5926 - loss: 0.6206 - val_accuracy: 0.8333 - val_loss: 0.6552\nEpoch 46/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6759 - loss: 0.5709 - val_accuracy: 0.8333 - val_loss: 0.6352\nEpoch 47/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7111 - loss: 0.5880 - val_accuracy: 0.8333 - val_loss: 0.6205\nEpoch 48/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7444 - loss: 0.5724 - val_accuracy: 0.8333 - val_loss: 0.6097\nEpoch 49/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6898 - loss: 0.5552 - val_accuracy: 0.8333 - val_loss: 0.6000\nEpoch 50/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6611 - loss: 0.5745 - val_accuracy: 0.8333 - val_loss: 0.5951\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8333 - loss: 0.5951\nTest accuracy for fold: 0.8333333134651184\nEpoch 1/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7278 - loss: 0.6378 - val_accuracy: 0.6667 - val_loss: 0.6763\nEpoch 2/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6509 - loss: 0.6011 - val_accuracy: 0.6667 - val_loss: 0.6626\nEpoch 3/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6139 - loss: 0.6069 - val_accuracy: 0.6667 - val_loss: 0.6522\nEpoch 4/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6806 - loss: 0.5424 - val_accuracy: 0.6667 - val_loss: 0.6452\nEpoch 5/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6324 - loss: 0.6092 - val_accuracy: 0.6667 - val_loss: 0.6395\nEpoch 6/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7176 - loss: 0.5101 - val_accuracy: 0.6667 - val_loss: 0.6335\nEpoch 7/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7120 - loss: 0.5407 - val_accuracy: 0.6667 - val_loss: 0.6269\nEpoch 8/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7750 - loss: 0.5093 - val_accuracy: 0.6667 - val_loss: 0.6207\nEpoch 9/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7759 - loss: 0.4539 - val_accuracy: 0.6667 - val_loss: 0.6260\nEpoch 10/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6954 - loss: 0.5095 - val_accuracy: 0.6667 - val_loss: 0.6258\nEpoch 11/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6694 - loss: 0.6003 - val_accuracy: 0.6667 - val_loss: 0.6029\nEpoch 12/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7741 - loss: 0.4932 - val_accuracy: 0.7778 - val_loss: 0.6132\nEpoch 13/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7602 - loss: 0.4736 - val_accuracy: 0.7778 - val_loss: 0.6210\nEpoch 14/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7333 - loss: 0.5163 - val_accuracy: 0.7778 - val_loss: 0.6038\nEpoch 15/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.5132 - val_accuracy: 0.6667 - val_loss: 0.5823\nEpoch 16/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6546 - loss: 0.6113 - val_accuracy: 0.6667 - val_loss: 0.5791\nEpoch 17/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8630 - loss: 0.4081 - val_accuracy: 0.6667 - val_loss: 0.5935\nEpoch 18/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6917 - loss: 0.5129 - val_accuracy: 0.6667 - val_loss: 0.5819\nEpoch 19/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7083 - loss: 0.5591 - val_accuracy: 0.6667 - val_loss: 0.5691\nEpoch 20/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8093 - loss: 0.3914 - val_accuracy: 0.7222 - val_loss: 0.5601\nEpoch 21/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7111 - loss: 0.5325 - val_accuracy: 0.7778 - val_loss: 0.5543\nEpoch 22/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7713 - loss: 0.4769 - val_accuracy: 0.7778 - val_loss: 0.5517\nEpoch 23/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7370 - loss: 0.5354 - val_accuracy: 0.7778 - val_loss: 0.5484\nEpoch 24/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7565 - loss: 0.5011 - val_accuracy: 0.7778 - val_loss: 0.5474\nEpoch 25/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7259 - loss: 0.5177 - val_accuracy: 0.7778 - val_loss: 0.5460\nEpoch 26/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7120 - loss: 0.4927 - val_accuracy: 0.7778 - val_loss: 0.5481\nEpoch 27/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7907 - loss: 0.6271 - val_accuracy: 0.7778 - val_loss: 0.5437\nEpoch 28/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7704 - loss: 0.5173 - val_accuracy: 0.7778 - val_loss: 0.5428\nEpoch 29/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7778 - loss: 0.4272 - val_accuracy: 0.6667 - val_loss: 0.5492\nEpoch 30/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7148 - loss: 0.6119 - val_accuracy: 0.7778 - val_loss: 0.5401\nEpoch 31/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7306 - loss: 0.6254 - val_accuracy: 0.7778 - val_loss: 0.5418\nEpoch 32/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7593 - loss: 0.5377 - val_accuracy: 0.7222 - val_loss: 0.5417\nEpoch 33/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7565 - loss: 0.5270 - val_accuracy: 0.7222 - val_loss: 0.5360\nEpoch 34/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7435 - loss: 0.5211 - val_accuracy: 0.7222 - val_loss: 0.5341\nEpoch 35/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7019 - loss: 0.5453 - val_accuracy: 0.7222 - val_loss: 0.5383\nEpoch 36/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7556 - loss: 0.4338 - val_accuracy: 0.6667 - val_loss: 0.5413\nEpoch 37/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7750 - loss: 0.5121 - val_accuracy: 0.7222 - val_loss: 0.5350\nEpoch 38/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7269 - loss: 0.4822 - val_accuracy: 0.7222 - val_loss: 0.5329\nEpoch 39/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7083 - loss: 0.5646 - val_accuracy: 0.7222 - val_loss: 0.5352\nEpoch 40/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7296 - loss: 0.5945 - val_accuracy: 0.7222 - val_loss: 0.5322\nEpoch 41/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8185 - loss: 0.4276 - val_accuracy: 0.7222 - val_loss: 0.5329\nEpoch 42/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6574 - loss: 0.5328 - val_accuracy: 0.7222 - val_loss: 0.5319\nEpoch 43/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8370 - loss: 0.4094 - val_accuracy: 0.7222 - val_loss: 0.5310\nEpoch 44/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8139 - loss: 0.3934 - val_accuracy: 0.7222 - val_loss: 0.5311\nEpoch 45/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7157 - loss: 0.4925 - val_accuracy: 0.7222 - val_loss: 0.5317\nEpoch 46/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7269 - loss: 0.4316 - val_accuracy: 0.6667 - val_loss: 0.5346\nEpoch 47/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7583 - loss: 0.4467 - val_accuracy: 0.6667 - val_loss: 0.5355\nEpoch 48/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7380 - loss: 0.4237 - val_accuracy: 0.7222 - val_loss: 0.5274\nEpoch 49/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7583 - loss: 0.5121 - val_accuracy: 0.7222 - val_loss: 0.5292\nEpoch 50/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7778 - loss: 0.5033 - val_accuracy: 0.7222 - val_loss: 0.5291\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7222 - loss: 0.5291\nTest accuracy for fold: 0.7222222089767456\nEpoch 1/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7407 - loss: 0.5176 - val_accuracy: 0.6667 - val_loss: 0.4384\nEpoch 2/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6463 - loss: 0.5834 - val_accuracy: 0.6667 - val_loss: 0.4362\nEpoch 3/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7593 - loss: 0.4841 - val_accuracy: 0.6667 - val_loss: 0.4356\nEpoch 4/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7204 - loss: 0.5102 - val_accuracy: 0.7222 - val_loss: 0.4388\nEpoch 5/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7741 - loss: 0.4387 - val_accuracy: 0.6667 - val_loss: 0.4389\nEpoch 6/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6713 - loss: 0.5179 - val_accuracy: 0.6667 - val_loss: 0.4477\nEpoch 7/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7426 - loss: 0.4914 - val_accuracy: 0.6667 - val_loss: 0.4533\nEpoch 8/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7546 - loss: 0.4539 - val_accuracy: 0.6667 - val_loss: 0.4506\nEpoch 9/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7083 - loss: 0.5001 - val_accuracy: 0.6667 - val_loss: 0.4460\nEpoch 10/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6981 - loss: 0.5506 - val_accuracy: 0.6667 - val_loss: 0.4457\nEpoch 11/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7593 - loss: 0.5236 - val_accuracy: 0.6667 - val_loss: 0.4466\nEpoch 12/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6981 - loss: 0.5092 - val_accuracy: 0.6667 - val_loss: 0.4499\nEpoch 13/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7167 - loss: 0.4685 - val_accuracy: 0.6667 - val_loss: 0.4528\nEpoch 14/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8009 - loss: 0.4197 - val_accuracy: 0.6667 - val_loss: 0.4542\nEpoch 15/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7963 - loss: 0.4892 - val_accuracy: 0.6667 - val_loss: 0.4561\nEpoch 16/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7787 - loss: 0.4839 - val_accuracy: 0.6667 - val_loss: 0.4546\nEpoch 17/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7722 - loss: 0.4186 - val_accuracy: 0.6667 - val_loss: 0.4517\nEpoch 18/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7435 - loss: 0.5212 - val_accuracy: 0.6667 - val_loss: 0.4533\nEpoch 19/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7528 - loss: 0.4977 - val_accuracy: 0.6667 - val_loss: 0.4584\nEpoch 20/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6963 - loss: 0.5317 - val_accuracy: 0.6667 - val_loss: 0.4658\nEpoch 21/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7259 - loss: 0.5176 - val_accuracy: 0.6667 - val_loss: 0.4665\nEpoch 22/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8389 - loss: 0.4240 - val_accuracy: 0.6667 - val_loss: 0.4591\nEpoch 23/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7657 - loss: 0.4967 - val_accuracy: 0.7222 - val_loss: 0.4788\nEpoch 24/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7241 - loss: 0.4865 - val_accuracy: 0.7222 - val_loss: 0.4890\nEpoch 25/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7083 - loss: 0.5263 - val_accuracy: 0.7222 - val_loss: 0.4855\nEpoch 26/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8019 - loss: 0.4672 - val_accuracy: 0.7222 - val_loss: 0.4675\nEpoch 27/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7278 - loss: 0.5012 - val_accuracy: 0.6667 - val_loss: 0.4552\nEpoch 28/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6685 - loss: 0.5078 - val_accuracy: 0.6667 - val_loss: 0.4570\nEpoch 29/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7602 - loss: 0.5103 - val_accuracy: 0.7222 - val_loss: 0.4769\nEpoch 30/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6444 - loss: 0.5704 - val_accuracy: 0.7222 - val_loss: 0.4817\nEpoch 31/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7611 - loss: 0.4216 - val_accuracy: 0.7222 - val_loss: 0.4671\nEpoch 32/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7315 - loss: 0.5051 - val_accuracy: 0.6667 - val_loss: 0.4450\nEpoch 33/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7093 - loss: 0.5077 - val_accuracy: 0.7222 - val_loss: 0.4332\nEpoch 34/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7194 - loss: 0.4790 - val_accuracy: 0.7222 - val_loss: 0.4264\nEpoch 35/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8222 - loss: 0.3912 - val_accuracy: 0.7222 - val_loss: 0.4255\nEpoch 36/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7528 - loss: 0.4698 - val_accuracy: 0.7222 - val_loss: 0.4247\nEpoch 37/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8593 - loss: 0.4263 - val_accuracy: 0.7222 - val_loss: 0.4266\nEpoch 38/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7222 - loss: 0.4663 - val_accuracy: 0.7222 - val_loss: 0.4261\nEpoch 39/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7093 - loss: 0.4704 - val_accuracy: 0.7222 - val_loss: 0.4271\nEpoch 40/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7111 - loss: 0.5264 - val_accuracy: 0.7222 - val_loss: 0.4298\nEpoch 41/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6852 - loss: 0.5693 - val_accuracy: 0.7222 - val_loss: 0.4270\nEpoch 42/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7491 - loss: 0.4787 - val_accuracy: 0.7222 - val_loss: 0.4271\nEpoch 43/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7102 - loss: 0.4863 - val_accuracy: 0.7222 - val_loss: 0.4357\nEpoch 44/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7435 - loss: 0.4206 - val_accuracy: 0.7222 - val_loss: 0.4305\nEpoch 45/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7833 - loss: 0.4214 - val_accuracy: 0.7222 - val_loss: 0.4318\nEpoch 46/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7037 - loss: 0.5361 - val_accuracy: 0.7222 - val_loss: 0.4311\nEpoch 47/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7185 - loss: 0.4891 - val_accuracy: 0.7222 - val_loss: 0.4269\nEpoch 48/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8056 - loss: 0.4354 - val_accuracy: 0.7778 - val_loss: 0.4199\nEpoch 49/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7241 - loss: 0.5316 - val_accuracy: 0.7778 - val_loss: 0.4175\nEpoch 50/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7407 - loss: 0.4818 - val_accuracy: 0.7778 - val_loss: 0.4200\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7778 - loss: 0.4200\nTest accuracy for fold: 0.7777777910232544\nEpoch 1/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7000 - loss: 0.5949 - val_accuracy: 0.7778 - val_loss: 0.4832\nEpoch 2/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7324 - loss: 0.5379 - val_accuracy: 0.7778 - val_loss: 0.4859\nEpoch 3/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7537 - loss: 0.4345 - val_accuracy: 0.7222 - val_loss: 0.5571\nEpoch 4/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8991 - loss: 0.3361 - val_accuracy: 0.7222 - val_loss: 0.5857\nEpoch 5/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8037 - loss: 0.4640 - val_accuracy: 0.7222 - val_loss: 0.5395\nEpoch 6/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7685 - loss: 0.4652 - val_accuracy: 0.7778 - val_loss: 0.5134\nEpoch 7/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7602 - loss: 0.4737 - val_accuracy: 0.7222 - val_loss: 0.5268\nEpoch 8/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8398 - loss: 0.4115 - val_accuracy: 0.7222 - val_loss: 0.5492\nEpoch 9/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7222 - loss: 0.4726 - val_accuracy: 0.7222 - val_loss: 0.5955\nEpoch 10/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7111 - loss: 0.4280 - val_accuracy: 0.7222 - val_loss: 0.5962\nEpoch 11/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7333 - loss: 0.4678 - val_accuracy: 0.7222 - val_loss: 0.5578\nEpoch 12/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7296 - loss: 0.4827 - val_accuracy: 0.7778 - val_loss: 0.5279\nEpoch 13/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7556 - loss: 0.4995 - val_accuracy: 0.7778 - val_loss: 0.5091\nEpoch 14/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7352 - loss: 0.4614 - val_accuracy: 0.7778 - val_loss: 0.5070\nEpoch 15/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7870 - loss: 0.4492 - val_accuracy: 0.7778 - val_loss: 0.5057\nEpoch 16/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7769 - loss: 0.4058 - val_accuracy: 0.7778 - val_loss: 0.5045\nEpoch 17/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7546 - loss: 0.5014 - val_accuracy: 0.7778 - val_loss: 0.5115\nEpoch 18/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7556 - loss: 0.4462 - val_accuracy: 0.7222 - val_loss: 0.5489\nEpoch 19/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8194 - loss: 0.4558 - val_accuracy: 0.7222 - val_loss: 0.5706\nEpoch 20/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7269 - loss: 0.4807 - val_accuracy: 0.7222 - val_loss: 0.5867\nEpoch 21/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7565 - loss: 0.4395 - val_accuracy: 0.7778 - val_loss: 0.5147\nEpoch 22/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7574 - loss: 0.4155 - val_accuracy: 0.7778 - val_loss: 0.5059\nEpoch 23/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7213 - loss: 0.5040 - val_accuracy: 0.7778 - val_loss: 0.5060\nEpoch 24/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8065 - loss: 0.4007 - val_accuracy: 0.7778 - val_loss: 0.5106\nEpoch 25/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8370 - loss: 0.4207 - val_accuracy: 0.7778 - val_loss: 0.5102\nEpoch 26/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6870 - loss: 0.4905 - val_accuracy: 0.7778 - val_loss: 0.5099\nEpoch 27/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8130 - loss: 0.3982 - val_accuracy: 0.7778 - val_loss: 0.5137\nEpoch 28/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7991 - loss: 0.4724 - val_accuracy: 0.7778 - val_loss: 0.5166\nEpoch 29/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7870 - loss: 0.4637 - val_accuracy: 0.7778 - val_loss: 0.5186\nEpoch 30/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7981 - loss: 0.4567 - val_accuracy: 0.7778 - val_loss: 0.5214\nEpoch 31/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7694 - loss: 0.4301 - val_accuracy: 0.7778 - val_loss: 0.5222\nEpoch 32/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8102 - loss: 0.4216 - val_accuracy: 0.7778 - val_loss: 0.5207\nEpoch 33/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7722 - loss: 0.4409 - val_accuracy: 0.7778 - val_loss: 0.5223\nEpoch 34/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.4889 - val_accuracy: 0.7778 - val_loss: 0.5235\nEpoch 35/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7769 - loss: 0.4501 - val_accuracy: 0.7222 - val_loss: 0.5602\nEpoch 36/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7741 - loss: 0.4667 - val_accuracy: 0.7222 - val_loss: 0.5737\nEpoch 37/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7685 - loss: 0.4327 - val_accuracy: 0.7222 - val_loss: 0.5723\nEpoch 38/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7611 - loss: 0.5246 - val_accuracy: 0.7778 - val_loss: 0.5480\nEpoch 39/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7981 - loss: 0.4253 - val_accuracy: 0.7778 - val_loss: 0.5806\nEpoch 40/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7759 - loss: 0.4027 - val_accuracy: 0.7222 - val_loss: 0.7289\nEpoch 41/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8204 - loss: 0.3529 - val_accuracy: 0.7222 - val_loss: 0.6666\nEpoch 42/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7287 - loss: 0.4451 - val_accuracy: 0.7778 - val_loss: 0.5799\nEpoch 43/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8185 - loss: 0.3984 - val_accuracy: 0.7222 - val_loss: 0.5861\nEpoch 44/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8093 - loss: 0.4327 - val_accuracy: 0.7778 - val_loss: 0.5702\nEpoch 45/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7685 - loss: 0.5105 - val_accuracy: 0.7778 - val_loss: 0.5516\nEpoch 46/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8491 - loss: 0.3654 - val_accuracy: 0.7778 - val_loss: 0.5581\nEpoch 47/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7204 - loss: 0.4152 - val_accuracy: 0.7778 - val_loss: 0.5632\nEpoch 48/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7657 - loss: 0.4332 - val_accuracy: 0.7778 - val_loss: 0.5518\nEpoch 49/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7454 - loss: 0.4640 - val_accuracy: 0.7222 - val_loss: 0.5601\nEpoch 50/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7787 - loss: 0.4307 - val_accuracy: 0.7222 - val_loss: 0.5684\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7222 - loss: 0.5684\nTest accuracy for fold: 0.7222222089767456\nEpoch 1/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6972 - loss: 0.5701 - val_accuracy: 0.8889 - val_loss: 0.3081\nEpoch 2/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7528 - loss: 0.5195 - val_accuracy: 0.8889 - val_loss: 0.3062\nEpoch 3/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7694 - loss: 0.4796 - val_accuracy: 0.8889 - val_loss: 0.3037\nEpoch 4/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7713 - loss: 0.4618 - val_accuracy: 0.8889 - val_loss: 0.3035\nEpoch 5/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8093 - loss: 0.4153 - val_accuracy: 0.8889 - val_loss: 0.3053\nEpoch 6/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.4575 - val_accuracy: 0.8889 - val_loss: 0.3056\nEpoch 7/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7722 - loss: 0.4896 - val_accuracy: 0.8889 - val_loss: 0.3028\nEpoch 8/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7398 - loss: 0.4991 - val_accuracy: 0.8889 - val_loss: 0.3016\nEpoch 9/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8019 - loss: 0.5551 - val_accuracy: 0.8889 - val_loss: 0.3038\nEpoch 10/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7722 - loss: 0.3945 - val_accuracy: 0.8889 - val_loss: 0.3063\nEpoch 11/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6648 - loss: 0.5186 - val_accuracy: 0.8889 - val_loss: 0.3005\nEpoch 12/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7861 - loss: 0.3973 - val_accuracy: 0.8889 - val_loss: 0.3032\nEpoch 13/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7648 - loss: 0.4823 - val_accuracy: 0.8889 - val_loss: 0.3074\nEpoch 14/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7370 - loss: 0.4703 - val_accuracy: 0.8889 - val_loss: 0.3068\nEpoch 15/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7241 - loss: 0.4829 - val_accuracy: 0.8889 - val_loss: 0.3056\nEpoch 16/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8185 - loss: 0.4662 - val_accuracy: 0.8889 - val_loss: 0.3047\nEpoch 17/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7843 - loss: 0.5003 - val_accuracy: 0.8889 - val_loss: 0.3028\nEpoch 18/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7380 - loss: 0.4862 - val_accuracy: 0.8889 - val_loss: 0.3028\nEpoch 19/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8130 - loss: 0.4568 - val_accuracy: 0.8889 - val_loss: 0.3116\nEpoch 20/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7815 - loss: 0.4517 - val_accuracy: 0.8889 - val_loss: 0.3145\nEpoch 21/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7204 - loss: 0.5166 - val_accuracy: 0.8889 - val_loss: 0.3085\nEpoch 22/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8593 - loss: 0.3770 - val_accuracy: 0.8889 - val_loss: 0.3048\nEpoch 23/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7093 - loss: 0.4900 - val_accuracy: 0.8889 - val_loss: 0.3012\nEpoch 24/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.5472 - val_accuracy: 0.8889 - val_loss: 0.2960\nEpoch 25/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8611 - loss: 0.3948 - val_accuracy: 0.8889 - val_loss: 0.2942\nEpoch 26/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8074 - loss: 0.4624 - val_accuracy: 0.8889 - val_loss: 0.2960\nEpoch 27/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8472 - loss: 0.3904 - val_accuracy: 0.8889 - val_loss: 0.2975\nEpoch 28/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8139 - loss: 0.3851 - val_accuracy: 0.8889 - val_loss: 0.2979\nEpoch 29/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7620 - loss: 0.4266 - val_accuracy: 0.8889 - val_loss: 0.2959\nEpoch 30/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7963 - loss: 0.4712 - val_accuracy: 0.8889 - val_loss: 0.2959\nEpoch 31/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8111 - loss: 0.4388 - val_accuracy: 0.8889 - val_loss: 0.2958\nEpoch 32/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8204 - loss: 0.4446 - val_accuracy: 0.9444 - val_loss: 0.2964\nEpoch 33/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8880 - loss: 0.3722 - val_accuracy: 0.9444 - val_loss: 0.2980\nEpoch 34/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7407 - loss: 0.4761 - val_accuracy: 0.9444 - val_loss: 0.3099\nEpoch 35/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7861 - loss: 0.5591 - val_accuracy: 0.9444 - val_loss: 0.3137\nEpoch 36/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7009 - loss: 0.5039 - val_accuracy: 0.9444 - val_loss: 0.3098\nEpoch 37/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7778 - loss: 0.4590 - val_accuracy: 0.9444 - val_loss: 0.3035\nEpoch 38/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7519 - loss: 0.4613 - val_accuracy: 0.9444 - val_loss: 0.2970\nEpoch 39/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8981 - loss: 0.3399 - val_accuracy: 0.9444 - val_loss: 0.2910\nEpoch 40/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7046 - loss: 0.5413 - val_accuracy: 0.9444 - val_loss: 0.2910\nEpoch 41/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8231 - loss: 0.3984 - val_accuracy: 0.9444 - val_loss: 0.2908\nEpoch 42/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8102 - loss: 0.4625 - val_accuracy: 0.9444 - val_loss: 0.2921\nEpoch 43/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7759 - loss: 0.4547 - val_accuracy: 0.9444 - val_loss: 0.2934\nEpoch 44/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8102 - loss: 0.3789 - val_accuracy: 0.9444 - val_loss: 0.2945\nEpoch 45/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8065 - loss: 0.4652 - val_accuracy: 0.9444 - val_loss: 0.2956\nEpoch 46/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7907 - loss: 0.4245 - val_accuracy: 0.9444 - val_loss: 0.2961\nEpoch 47/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6935 - loss: 0.5575 - val_accuracy: 0.9444 - val_loss: 0.2964\nEpoch 48/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7861 - loss: 0.4918 - val_accuracy: 0.9444 - val_loss: 0.2940\nEpoch 49/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7074 - loss: 0.6002 - val_accuracy: 0.9444 - val_loss: 0.2922\nEpoch 50/50\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8083 - loss: 0.4328 - val_accuracy: 0.9444 - val_loss: 0.3026\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9444 - loss: 0.3026\nTest accuracy for fold: 0.9444444179534912\n","output_type":"stream"}],"execution_count":482},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(X_test, y_test)\nprint(f'Test accuracy: {test_acc}')\nk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:33:03.020743Z","iopub.execute_input":"2024-12-15T16:33:03.021096Z","iopub.status.idle":"2024-12-15T16:33:03.115453Z","shell.execute_reply.started":"2024-12-15T16:33:03.021062Z","shell.execute_reply":"2024-12-15T16:33:03.114015Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9444 - loss: 0.3026\nTest accuracy: 0.9444444179534912\n","output_type":"stream"}],"execution_count":483},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = model.predict(X_test)\n\n# Convert the predictions back to class labels\ny_pred_labels = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n\n# Decode the labels back to original classes\npredicted_classes = label_encoder.inverse_transform(y_pred_labels)\n\nprint(predicted_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:33:03.116863Z","iopub.execute_input":"2024-12-15T16:33:03.117313Z","iopub.status.idle":"2024-12-15T16:33:03.483349Z","shell.execute_reply.started":"2024-12-15T16:33:03.117276Z","shell.execute_reply":"2024-12-15T16:33:03.482167Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n['trend' 'trend' 'trend' 'trend' 'micro trend' 'micro trend' 'trend'\n 'no trend' 'no trend' 'micro trend' 'no trend' 'micro trend'\n 'micro trend' 'trend' 'micro trend' 'micro trend' 'micro trend' 'trend']\n","output_type":"stream"}],"execution_count":484},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Step 1: Make predictions\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n\n# Step 2: Generate confusion matrix\ncm = confusion_matrix(y_test, y_pred_classes)\n\n# Step 3: Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n# print(len(X_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:33:03.486131Z","iopub.execute_input":"2024-12-15T16:33:03.486477Z","iopub.status.idle":"2024-12-15T16:33:03.862609Z","shell.execute_reply.started":"2024-12-15T16:33:03.486443Z","shell.execute_reply":"2024-12-15T16:33:03.861518Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}}],"execution_count":485}]}